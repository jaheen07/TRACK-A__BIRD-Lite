{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "T8Ja2ZIjq-Rm"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from dataclasses import asdict, dataclass\n",
        "from pathlib import Path\n",
        "from typing import List, Optional, Tuple\n",
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zJpMfFR2rIU1"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class LineSegment:\n",
        "    pt1: Tuple[int, int]\n",
        "    pt2: Tuple[int, int]\n",
        "    length: float\n",
        "    angle: float\n",
        "    label: str\n",
        "\n",
        "@dataclass\n",
        "class Rectangle:\n",
        "    x: int\n",
        "    y: int\n",
        "    w: int\n",
        "    h: int\n",
        "    area: int\n",
        "    aspect_ratio: float\n",
        "    label: str\n",
        "    confidence: float\n",
        "\n",
        "@dataclass\n",
        "class Roof:\n",
        "    roof_type: str\n",
        "    apex: Optional[Tuple[int, int]]\n",
        "    points: List[Tuple[int, int]]\n",
        "    lines: List[dict]\n",
        "\n",
        "@dataclass\n",
        "class DetectionResult:\n",
        "    image_file: str\n",
        "    image_size: Tuple[int, int]\n",
        "    line_segments: List[dict]\n",
        "    rectangles: List[dict]\n",
        "    roof: Optional[dict]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vbtiJDSGrOfN"
      },
      "outputs": [],
      "source": [
        "def to_gray(img: np.ndarray) -> np.ndarray:\n",
        "    return cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) if img.ndim == 3 else img.copy()\n",
        "\n",
        "def point_distance(p1: Tuple[int, int], p2: Tuple[int, int]) -> float:\n",
        "    return float(np.hypot(p1[0] - p2[0], p1[1] - p2[1]))\n",
        "\n",
        "def classify_line(angle: float) -> str:\n",
        "    abs_angle = abs(angle)\n",
        "    if abs_angle < 10 or abs_angle > 170:\n",
        "        return \"horizontal\"\n",
        "    if 80 < abs_angle < 100:\n",
        "        return \"vertical\"\n",
        "    return \"diagonal\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Correct Rotated images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iAHokc54xQtm"
      },
      "outputs": [],
      "source": [
        "def detect_rotation_angle(image: np.ndarray) -> float:\n",
        "    gray = to_gray(image)\n",
        "    binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)[1]\n",
        "    lines = cv2.HoughLines(cv2.Canny(binary, 50, 150), 1, np.pi / 180, 100)\n",
        "    if lines is None:\n",
        "        return 0.0\n",
        "\n",
        "    angles = []\n",
        "    for line in lines:\n",
        "        theta = np.degrees(line[0][1])\n",
        "        if theta <= 45:\n",
        "            angles.append(theta)\n",
        "        elif theta >= 135:\n",
        "            angles.append(theta - 180)\n",
        "        else:\n",
        "            angles.append(theta - 90)\n",
        "    return float(np.median(angles)) if angles else 0.0\n",
        "\n",
        "\n",
        "def correct_rotation(image: np.ndarray, angle: float) -> np.ndarray:\n",
        "    if abs(angle) < 0.5:\n",
        "        return image\n",
        "    h, w = image.shape[:2]\n",
        "    matrix = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)\n",
        "    border = (255, 255, 255) if image.ndim == 3 else 255\n",
        "    return cv2.warpAffine(image, matrix, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=border)\n",
        "\n",
        "\n",
        "def run_rotation_correction(dataset_dir: str, output_dir: str, threshold: float = 2.0) -> dict:\n",
        "    dataset_path = Path(dataset_dir)\n",
        "    output_path = Path(output_dir)\n",
        "    output_path.mkdir(exist_ok=True)\n",
        "\n",
        "    image_files = sorted(dataset_path.glob(\"*.png\"))\n",
        "    report = {\"threshold_degrees\": threshold, \"images\": []}\n",
        "    rotated_count = 0\n",
        "\n",
        "    for img_path in image_files:\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        angle = detect_rotation_angle(img)\n",
        "        is_rotated = abs(angle) >= threshold\n",
        "        if is_rotated:\n",
        "            rotated_count += 1\n",
        "            img = correct_rotation(img, angle)\n",
        "\n",
        "        cv2.imwrite(str(output_path / img_path.name), img)\n",
        "        report[\"images\"].append({\n",
        "            \"file\": img_path.name,\n",
        "            \"detected_angle\": round(angle, 2),\n",
        "            \"is_rotated\": is_rotated,\n",
        "            \"corrected\": is_rotated,\n",
        "        })\n",
        "\n",
        "    report[\"summary\"] = {\n",
        "        \"total_images\": len(image_files),\n",
        "        \"rotated_images\": rotated_count,\n",
        "        \"straight_images\": len(image_files) - rotated_count,\n",
        "    }\n",
        "    return report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preprocesses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lpvoobvGxi0O"
      },
      "outputs": [],
      "source": [
        "def preprocess_for_detection(img: np.ndarray) -> np.ndarray:\n",
        "    binary = cv2.threshold(to_gray(img), 200, 255, cv2.THRESH_BINARY_INV)[1]\n",
        "    connected = cv2.dilate(binary, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)), iterations=1)\n",
        "    kernels = [\n",
        "        cv2.getStructuringElement(cv2.MORPH_RECT, (15, 1)),\n",
        "        cv2.getStructuringElement(cv2.MORPH_RECT, (1, 15)),\n",
        "        np.eye(11, dtype=np.uint8),\n",
        "        np.flipud(np.eye(11, dtype=np.uint8)),\n",
        "    ]\n",
        "    combined = np.zeros_like(connected)\n",
        "    for kernel in kernels:\n",
        "        combined = cv2.bitwise_or(combined, cv2.morphologyEx(connected, cv2.MORPH_CLOSE, kernel))\n",
        "    return cv2.morphologyEx(combined, cv2.MORPH_OPEN, cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2)))\n",
        "\n",
        "\n",
        "def thin_binary_mask(binary: np.ndarray) -> np.ndarray:\n",
        "    if hasattr(cv2, \"ximgproc\") and hasattr(cv2.ximgproc, \"thinning\"):\n",
        "        return cv2.ximgproc.thinning(binary)\n",
        "    skeleton = np.zeros_like(binary)\n",
        "    work = binary.copy()\n",
        "    element = cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3))\n",
        "    while True:\n",
        "        eroded = cv2.erode(work, element)\n",
        "        opened = cv2.dilate(eroded, element)\n",
        "        residue = cv2.subtract(work, opened)\n",
        "        skeleton = cv2.bitwise_or(skeleton, residue)\n",
        "        work = eroded\n",
        "        if cv2.countNonZero(work) == 0:\n",
        "            return skeleton"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Segment distance and angle calculation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "i4bdPRSUx35F"
      },
      "outputs": [],
      "source": [
        "def segment_distance(seg1: LineSegment, seg2: LineSegment) -> float:\n",
        "    return min(\n",
        "        point_distance(seg1.pt1, seg2.pt1),\n",
        "        point_distance(seg1.pt1, seg2.pt2),\n",
        "        point_distance(seg1.pt2, seg2.pt1),\n",
        "        point_distance(seg1.pt2, seg2.pt2),\n",
        "    )\n",
        "\n",
        "def angle_difference(a1: float, a2: float) -> float:\n",
        "    diff = abs(a1 - a2)\n",
        "    diff = min(diff, 360 - diff)\n",
        "    return min(diff, abs(180 - diff))\n",
        "\n",
        "def segments_are_similar(seg1: LineSegment, seg2: LineSegment, angle_thresh: float, dist_thresh: float) -> bool:\n",
        "    return angle_difference(seg1.angle, seg2.angle) <= angle_thresh and segment_distance(seg1, seg2) <= dist_thresh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reduce similar segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Z-mLwATlBsbG"
      },
      "outputs": [],
      "source": [
        "def merge_segment_group(group: List[LineSegment]) -> LineSegment:\n",
        "    points = [pt for seg in group for pt in (seg.pt1, seg.pt2)]\n",
        "    best_pair = (points[0], points[-1])\n",
        "    best_dist = 0.0\n",
        "    for i, p1 in enumerate(points):\n",
        "        for p2 in points[i + 1 :]:\n",
        "            d = point_distance(p1, p2)\n",
        "            if d > best_dist:\n",
        "                best_dist = d\n",
        "                best_pair = (p1, p2)\n",
        "\n",
        "    pt1, pt2 = best_pair\n",
        "    angle = float(np.degrees(np.arctan2(pt2[1] - pt1[1], pt2[0] - pt1[0])))\n",
        "    return LineSegment(pt1, pt2, round(best_dist, 2), round(angle, 2), classify_line(angle))\n",
        "\n",
        "\n",
        "def merge_similar_segments(segments: List[LineSegment], angle_thresh: float = 10, dist_thresh: float = 20) -> List[LineSegment]:\n",
        "    if len(segments) < 2:\n",
        "        return segments\n",
        "\n",
        "    merged, used = [], [False] * len(segments)\n",
        "    for i, seg1 in enumerate(segments):\n",
        "        if used[i]:\n",
        "            continue\n",
        "        group = [seg1]\n",
        "        queue = [seg1]\n",
        "        used[i] = True\n",
        "\n",
        "\n",
        "        while queue:                                                          # BFS-style grouping so chains of close segments merge into one line.\n",
        "            base = queue.pop()\n",
        "            for j, seg2 in enumerate(segments):\n",
        "                if used[j]:\n",
        "                    continue\n",
        "                if segments_are_similar(base, seg2, angle_thresh, dist_thresh):\n",
        "                    group.append(seg2)\n",
        "                    queue.append(seg2)\n",
        "                    used[j] = True\n",
        "\n",
        "        merged.append(merge_segment_group(group) if len(group) > 1 else seg1)\n",
        "    return merged"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "KYfSurm8CL_2"
      },
      "outputs": [],
      "source": [
        "def point_to_line_distance(point: Tuple[int, int], seg: LineSegment) -> float:\n",
        "    x0, y0 = point\n",
        "    x1, y1 = seg.pt1\n",
        "    x2, y2 = seg.pt2\n",
        "    denom = np.hypot(x2 - x1, y2 - y1)\n",
        "    if denom == 0:\n",
        "        return point_distance(point, seg.pt1)\n",
        "    return abs((y2 - y1) * x0 - (x2 - x1) * y0 + x2 * y1 - y2 * x1) / denom\n",
        "\n",
        "\n",
        "def segment_overlap_ratio(seg1: LineSegment, seg2: LineSegment) -> float:\n",
        "    dx = abs(seg1.pt2[0] - seg1.pt1[0])\n",
        "    dy = abs(seg1.pt2[1] - seg1.pt1[1])\n",
        "    if dx >= dy:\n",
        "        a1, a2 = sorted((seg1.pt1[0], seg1.pt2[0]))\n",
        "        b1, b2 = sorted((seg2.pt1[0], seg2.pt2[0]))\n",
        "    else:\n",
        "        a1, a2 = sorted((seg1.pt1[1], seg1.pt2[1]))\n",
        "        b1, b2 = sorted((seg2.pt1[1], seg2.pt2[1]))\n",
        "\n",
        "    overlap = max(0, min(a2, b2) - max(a1, b1))\n",
        "    shorter = max(1, min(a2 - a1, b2 - b1))\n",
        "    return overlap / shorter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "eDC_7cuuCNMl"
      },
      "outputs": [],
      "source": [
        "def is_duplicate_segment(seg: LineSegment, ref: LineSegment, angle_thresh: float = 6, offset_thresh: float = 6) -> bool:\n",
        "    if seg.label != ref.label:\n",
        "        return False\n",
        "    if angle_difference(seg.angle, ref.angle) > angle_thresh:\n",
        "        return False\n",
        "    if point_to_line_distance(seg.pt1, ref) > offset_thresh or point_to_line_distance(seg.pt2, ref) > offset_thresh:\n",
        "        return False\n",
        "    return segment_overlap_ratio(seg, ref) > 0.6\n",
        "\n",
        "\n",
        "def suppress_duplicate_segments(segments: List[LineSegment]) -> List[LineSegment]:\n",
        "    kept: List[LineSegment] = []\n",
        "    for seg in sorted(segments, key=lambda s: s.length, reverse=True):\n",
        "        if any(is_duplicate_segment(seg, ref) for ref in kept):\n",
        "            continue\n",
        "        kept.append(seg)\n",
        "    return kept\n",
        "\n",
        "def detect_line_segments(binary: np.ndarray) -> List[LineSegment]:\n",
        "    line_mask = thin_binary_mask(binary)\n",
        "    h, w = line_mask.shape[:2]\n",
        "    min_dim = min(h, w)\n",
        "    vote_threshold = max(35, int(min_dim * 0.08))\n",
        "    min_line_length = max(25, int(min_dim * 0.07))\n",
        "    max_line_gap = max(8, int(min_dim * 0.02))\n",
        "    lines = cv2.HoughLinesP(\n",
        "        cv2.Canny(line_mask, 50, 150),\n",
        "        1,\n",
        "        np.pi / 180,\n",
        "        vote_threshold,\n",
        "        minLineLength=min_line_length,\n",
        "        maxLineGap=max_line_gap,\n",
        "    )\n",
        "    if lines is None:\n",
        "        return []\n",
        "\n",
        "    segments = []\n",
        "    for line in lines:\n",
        "        x1, y1, x2, y2 = line[0]\n",
        "        length = point_distance((x1, y1), (x2, y2))\n",
        "        if length < 15:\n",
        "            continue\n",
        "        angle = float(np.degrees(np.arctan2(y2 - y1, x2 - x1)))\n",
        "        segments.append(LineSegment((int(x1), int(y1)), (int(x2), int(y2)), round(length, 2), round(angle, 2), classify_line(angle)))\n",
        "    merged = merge_similar_segments(segments, angle_thresh=8, dist_thresh=28)\n",
        "    return suppress_duplicate_segments(merged)\n",
        "\n",
        "\n",
        "def points_close(p1: Tuple[int, int], p2: Tuple[int, int], threshold: float = 15) -> bool:\n",
        "    return point_distance(p1, p2) < threshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwDzGoj-CuDj"
      },
      "source": [
        "Classify Roof(Triangle/flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "lKAfOUg9CanF"
      },
      "outputs": [],
      "source": [
        "def detect_triangle_roof(diagonals: List[LineSegment]) -> Optional[Roof]:\n",
        "    if len(diagonals) < 2:\n",
        "        return None\n",
        "\n",
        "    slant_left, slant_right = [], []\n",
        "    for seg in diagonals:\n",
        "        top, bottom = (seg.pt1, seg.pt2) if seg.pt1[1] < seg.pt2[1] else (seg.pt2, seg.pt1)\n",
        "        if abs(top[1] - bottom[1]) <= 20:\n",
        "            continue\n",
        "        (slant_left if top[0] > bottom[0] else slant_right).append((seg, top, bottom))\n",
        "\n",
        "    if not slant_left or not slant_right:\n",
        "        return None\n",
        "\n",
        "    best_pair, best_top_dist = None, float(\"inf\")\n",
        "    for left_seg, left_top, left_bottom in slant_left:\n",
        "        for right_seg, right_top, right_bottom in slant_right:\n",
        "            top_dist = point_distance(left_top, right_top)\n",
        "            if top_dist < 50 and left_bottom[0] < right_bottom[0] and top_dist < best_top_dist:\n",
        "                apex = ((left_top[0] + right_top[0]) // 2, (left_top[1] + right_top[1]) // 2)\n",
        "                best_pair = (left_seg, right_seg, apex, left_bottom, right_bottom)\n",
        "                best_top_dist = top_dist\n",
        "\n",
        "    if best_pair is None:\n",
        "        return None\n",
        "\n",
        "    left_seg, right_seg, apex, left_bottom, right_bottom = best_pair\n",
        "    lines = [\n",
        "        {\"pt1\": left_seg.pt1, \"pt2\": left_seg.pt2, \"label\": \"roof\"},\n",
        "        {\"pt1\": right_seg.pt1, \"pt2\": right_seg.pt2, \"label\": \"roof\"},\n",
        "    ]\n",
        "    return Roof(\"triangle\", apex, [left_bottom, apex, right_bottom], lines)\n",
        "\n",
        "\n",
        "def detect_flat_roof(horizontals: List[LineSegment], img_w: int) -> Optional[Roof]:\n",
        "    if not horizontals:\n",
        "        return None\n",
        "\n",
        "    top_lines = sorted(horizontals, key=lambda s: min(s.pt1[1], s.pt2[1]))\n",
        "    for i in range(len(top_lines) - 1):\n",
        "        line1, line2 = top_lines[i], top_lines[i + 1]\n",
        "        y1, y2 = min(line1.pt1[1], line1.pt2[1]), min(line2.pt1[1], line2.pt2[1])\n",
        "        if abs(y2 - y1) >= 30:\n",
        "            continue\n",
        "\n",
        "        x1_min, x1_max = sorted((line1.pt1[0], line1.pt2[0]))\n",
        "        x2_min, x2_max = sorted((line2.pt1[0], line2.pt2[0]))\n",
        "        if (x1_max - x1_min) > img_w * 0.3 and (x2_max - x2_min) > img_w * 0.3:\n",
        "            points = [(x1_min, y1), (x1_max, y1), (x2_min, y2), (x2_max, y2)]\n",
        "            lines = [\n",
        "                {\"pt1\": line1.pt1, \"pt2\": line1.pt2, \"label\": \"roof\"},\n",
        "                {\"pt1\": line2.pt1, \"pt2\": line2.pt2, \"label\": \"roof\"},\n",
        "            ]\n",
        "            return Roof(\"flat\", None, points, lines)\n",
        "\n",
        "    line = top_lines[0]\n",
        "    x_min, x_max = sorted((line.pt1[0], line.pt2[0]))\n",
        "    y = min(line.pt1[1], line.pt2[1])\n",
        "    if (x_max - x_min) > img_w * 0.4:\n",
        "        return Roof(\"flat\", None, [(x_min, y), (x_max, y)], [{\"pt1\": line.pt1, \"pt2\": line.pt2, \"label\": \"roof\"}])\n",
        "    return None\n",
        "\n",
        "\n",
        "def label_roof_segments(segments: List[LineSegment], roof: Roof) -> List[LineSegment]:\n",
        "    output = []\n",
        "    for seg in segments:\n",
        "        label = seg.label\n",
        "        for roof_line in roof.lines:\n",
        "            match_fwd = points_close(seg.pt1, roof_line[\"pt1\"]) and points_close(seg.pt2, roof_line[\"pt2\"])\n",
        "            match_rev = points_close(seg.pt1, roof_line[\"pt2\"]) and points_close(seg.pt2, roof_line[\"pt1\"])\n",
        "            if match_fwd or match_rev:\n",
        "                label = \"roof\"\n",
        "                break\n",
        "        output.append(LineSegment(seg.pt1, seg.pt2, seg.length, seg.angle, label))\n",
        "    return output\n",
        "\n",
        "\n",
        "def detect_roof(segments: List[LineSegment], img_shape: Tuple[int, int]) -> Tuple[Optional[Roof], List[LineSegment]]:\n",
        "    img_h, img_w = img_shape\n",
        "    top_threshold = img_h * 0.35\n",
        "\n",
        "    top_diagonals = [s for s in segments if s.label == \"diagonal\" and min(s.pt1[1], s.pt2[1]) < top_threshold]\n",
        "    top_horizontals = [\n",
        "        s for s in segments\n",
        "        if s.label == \"horizontal\" and min(s.pt1[1], s.pt2[1]) < top_threshold and max(s.pt1[1], s.pt2[1]) < top_threshold\n",
        "    ]\n",
        "\n",
        "    roof = detect_triangle_roof(top_diagonals) or detect_flat_roof(top_horizontals, img_w)\n",
        "    return (roof, label_roof_segments(segments, roof)) if roof else (None, segments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "IoU computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "i8UJUpMsC-be"
      },
      "outputs": [],
      "source": [
        "def compute_iou(rect1: Rectangle, rect2: Rectangle) -> float:\n",
        "    x1, y1 = max(rect1.x, rect2.x), max(rect1.y, rect2.y)\n",
        "    x2, y2 = min(rect1.x + rect1.w, rect2.x + rect2.w), min(rect1.y + rect1.h, rect2.y + rect2.h)\n",
        "    if x2 <= x1 or y2 <= y1:\n",
        "        return 0.0\n",
        "\n",
        "    intersection = (x2 - x1) * (y2 - y1)\n",
        "    union = rect1.w * rect1.h + rect2.w * rect2.h - intersection\n",
        "    return intersection / union if union > 0 else 0.0\n",
        "\n",
        "\n",
        "def is_contained(inner: Rectangle, outer: Rectangle) -> bool:\n",
        "    return (\n",
        "        inner.x >= outer.x\n",
        "        and inner.y >= outer.y\n",
        "        and inner.x + inner.w <= outer.x + outer.w\n",
        "        and inner.y + inner.h <= outer.y + outer.h\n",
        "        and inner.area < outer.area * 0.8\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Rectangle structure detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "hUaBB_uNDX_9"
      },
      "outputs": [],
      "source": [
        "def filter_rectangles(rectangles: List[Rectangle]) -> List[Rectangle]:\n",
        "    if len(rectangles) < 2:\n",
        "        return rectangles\n",
        "\n",
        "    sorted_rects = sorted(rectangles, key=lambda r: r.area)\n",
        "    filtered: List[Rectangle] = []\n",
        "    for rect in sorted_rects:\n",
        "        duplicate = False\n",
        "        for existing in filtered[:]:\n",
        "            if compute_iou(rect, existing) > 0.5:\n",
        "                duplicate = True\n",
        "                break\n",
        "            if is_contained(rect, existing) or is_contained(existing, rect):\n",
        "                if rect.area < existing.area:\n",
        "                    filtered.remove(existing)\n",
        "                else:\n",
        "                    duplicate = True\n",
        "                break\n",
        "        if not duplicate:\n",
        "            filtered.append(rect)\n",
        "    return filtered\n",
        "\n",
        "\n",
        "def detect_rectangles(binary: np.ndarray, img_shape: Tuple[int, int], roof: Optional[Roof]) -> List[Rectangle]:\n",
        "    img_h, img_w = img_shape\n",
        "    roof_bottom_y = max(p[1] for p in roof.points) + 10 if roof else 0\n",
        "\n",
        "    contours, hierarchy = cv2.findContours(cv2.bitwise_not(binary), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if hierarchy is None:\n",
        "        return []\n",
        "\n",
        "    rectangles = []\n",
        "    for i, contour in enumerate(contours):\n",
        "        area = cv2.contourArea(contour)\n",
        "        if area < 100 or area > img_h * img_w * 0.8:\n",
        "            continue\n",
        "\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        rect_area = w * h\n",
        "        if rect_area == 0 or area / rect_area < 0.6:\n",
        "            continue\n",
        "\n",
        "        approx = cv2.approxPolyDP(contour, 0.02 * cv2.arcLength(contour, True), True)\n",
        "        if len(approx) < 4 or len(approx) > 8:\n",
        "            continue\n",
        "        if y < roof_bottom_y and y + h < roof_bottom_y + 20:\n",
        "            continue\n",
        "\n",
        "        detected = classify_rectangle(x, y, w, h, img_w, img_h, hierarchy[0][i], roof_bottom_y)\n",
        "        if detected is None:\n",
        "            continue\n",
        "        label, confidence = detected\n",
        "        rectangles.append(Rectangle(int(x), int(y), int(w), int(h), int(area), round(w / h if h > 0 else 0.0, 2), label, round(confidence, 2)))\n",
        "    return filter_rectangles(rectangles)\n",
        "\n",
        "\n",
        "def detect_structures(img: np.ndarray, filename: str = \"\") -> DetectionResult:\n",
        "    h, w = img.shape[:2]\n",
        "    binary = preprocess_for_detection(img)\n",
        "    segments = detect_line_segments(binary)\n",
        "    roof, segments = detect_roof(segments, (h, w))\n",
        "    rectangles = detect_rectangles(binary, (h, w), roof)\n",
        "    return DetectionResult(filename, (w, h), [asdict(s) for s in segments], [asdict(r) for r in rectangles], asdict(roof) if roof else None)\n",
        "\n",
        "def classify_rectangle(\n",
        "    x: int,\n",
        "    y: int,\n",
        "    w: int,\n",
        "    h: int,\n",
        "    img_w: int,\n",
        "    img_h: int,\n",
        "    hierarchy_info: np.ndarray,\n",
        "    roof_bottom_y: int,\n",
        ") -> Optional[Tuple[str, float]]:\n",
        "    area = w * h\n",
        "    aspect = w / h if h > 0 else 1.0\n",
        "    relative_area = area / (img_w * img_h)\n",
        "    relative_y = (y + h / 2) / img_h\n",
        "\n",
        "    # if relative_area > 0.3 and hierarchy_info[3] < 0:\n",
        "    #     return \"building_outline\", 0.8\n",
        "    if relative_y > 0.6 and aspect < 1.5 and 0.01 < relative_area < 0.15:\n",
        "        return \"door\", 0.85 if relative_y > 0.75 else 0.7\n",
        "    if 0.002 < relative_area < 0.08 and y > roof_bottom_y and relative_y < 0.85:\n",
        "        return \"window\", 0.8 if 0.5 < aspect < 2.0 else 0.7\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cXPZ-b7DckN"
      },
      "source": [
        "Vizualize the outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hZPQX4qtDZGd"
      },
      "outputs": [],
      "source": [
        "def visualize_detections(img: np.ndarray, result: DetectionResult, output_path: Optional[str] = None) -> np.ndarray:\n",
        "    vis = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR) if img.ndim == 2 else img.copy()\n",
        "    colors = {\n",
        "        \"horizontal\": (255, 0, 0),\n",
        "        \"vertical\": (255, 0, 0),\n",
        "        \"diagonal\": (255, 128, 0),\n",
        "        \"roof\": (0, 165, 255),\n",
        "        \"window\": (0, 106, 78),\n",
        "        \"door\": (65, 105, 225),\n",
        "    }\n",
        "\n",
        "    for seg in result.line_segments:\n",
        "        thickness = 3 if seg[\"label\"] == \"roof\" else 2\n",
        "        cv2.line(vis, tuple(seg[\"pt1\"]), tuple(seg[\"pt2\"]), colors.get(seg[\"label\"], (255, 0, 0)), thickness)\n",
        "        cv2.circle(vis, tuple(seg[\"pt1\"]), 4, (0, 255, 0), -1)\n",
        "        cv2.circle(vis, tuple(seg[\"pt2\"]), 4, (0, 255, 0), -1)\n",
        "\n",
        "    if result.roof:\n",
        "        roof = result.roof\n",
        "        if roof[\"roof_type\"] == \"triangle\" and roof[\"apex\"]:\n",
        "            apex = tuple(roof[\"apex\"])\n",
        "            cv2.circle(vis, apex, 8, (0, 0, 255), -1)\n",
        "            cv2.putText(vis, \"ROOF (triangle)\", (apex[0] - 50, apex[1] - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "        elif roof[\"roof_type\"] == \"flat\" and roof[\"points\"]:\n",
        "            top_y = min(p[1] for p in roof[\"points\"])\n",
        "            center_x = sum(p[0] for p in roof[\"points\"]) // len(roof[\"points\"])\n",
        "            cv2.putText(vis, \"ROOF (flat)\", (center_x - 40, top_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "\n",
        "    for rect in result.rectangles:\n",
        "        x, y, w, h = rect[\"x\"], rect[\"y\"], rect[\"w\"], rect[\"h\"]\n",
        "        color = colors.get(rect[\"label\"], (128, 128, 128))\n",
        "        cv2.rectangle(vis, (x, y), (x + w, y + h), color, 2)\n",
        "        text = f\"{rect['label']} ({rect['confidence']:.0%})\"\n",
        "        (text_w, text_h), _ = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.4, 1)\n",
        "        cv2.rectangle(vis, (x, y - text_h - 4), (x + text_w + 4, y), color, -1)\n",
        "        cv2.putText(vis, text, (x + 2, y - 2), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
        "\n",
        "    if output_path:\n",
        "        cv2.imwrite(output_path, vis)\n",
        "    return vis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Main Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Cl8aWWRYDmm9"
      },
      "outputs": [],
      "source": [
        "def run_structure_detection(dataset_dir: str, output_dir: str, detections_file: str) -> dict:\n",
        "    dataset_path = Path(dataset_dir)\n",
        "    output_path = Path(output_dir)\n",
        "    output_path.mkdir(exist_ok=True)\n",
        "\n",
        "    results = {\"detections\": []}\n",
        "    for img_path in sorted(dataset_path.glob(\"*.png\")):\n",
        "        img = cv2.imread(str(img_path))\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        detected = detect_structures(img, img_path.name)\n",
        "        results[\"detections\"].append(asdict(detected))\n",
        "        visualize_detections(img, detected, str(output_path / f\"vis_{img_path.name}\"))\n",
        "\n",
        "    with open(detections_file, \"w\") as file:\n",
        "        json.dump(results, file, indent=2)\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "DLr62CrCDnmV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Total: 32 images\n",
            "  Rotated: 8\n",
            "Process complete\n"
          ]
        }
      ],
      "source": [
        "def run_pipeline(\n",
        "    dataset_dir: str = \"dataset\",\n",
        "    preprocessed_dir: str = \"preprocessed\",\n",
        "    output_dir: str = \"detections_output\",\n",
        "    detections_file: str = \"detections.json\",\n",
        "    rotation_threshold: float = 2.0,\n",
        ") -> dict:\n",
        "    rotation_report = run_rotation_correction(dataset_dir, preprocessed_dir, rotation_threshold)\n",
        "    print(f\"  Total: {rotation_report['summary']['total_images']} images\")\n",
        "    print(f\"  Rotated: {rotation_report['summary']['rotated_images']}\")\n",
        "    detection_results = run_structure_detection(preprocessed_dir, output_dir, detections_file)\n",
        "    print(\"Process complete\")\n",
        "    return {\"rotation\": rotation_report, \"detections\": detection_results}\n",
        "\n",
        "def main(\n",
        "    dataset: str = \"dataset\",\n",
        "    preprocessed: str = \"preprocessed\",\n",
        "    output: str = \"detections_output\",\n",
        "    json_file: str = \"detections.json\",\n",
        "    threshold: float = 2.0\n",
        ") -> None:\n",
        "    run_pipeline(dataset, preprocessed, output, json_file, threshold)\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
